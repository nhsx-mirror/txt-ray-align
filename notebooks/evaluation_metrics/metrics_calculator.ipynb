{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML NLP Metrics Calculation\n",
    "# This notebook contains four examples from the IU Chest X-ray dataset - https://openi.nlm.nih.gov/faq#collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d508367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages - uncomment to install\n",
    "# !python -m pip install datasets nltk sacrebleu rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b71178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from warnings import simplefilter\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17ee4165",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = list(\n",
    "    zip(sorted(glob.glob(\"./txt/ref_*.txt\")), sorted(glob.glob(\"./txt/gen_*.txt\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffae900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, (ref, gen) in enumerate(test_cases):\n",
    "    print(f\"Test Case {n+1}\")\n",
    "    print(f\"(Ref: {ref} + Gen: {gen})\")\n",
    "    print()\n",
    "\n",
    "    with open(ref, \"r\") as f:\n",
    "        ref_case = f.readlines()\n",
    "\n",
    "    ref_case = \".\".join(map(str, ref_case))\n",
    "    ref_case = ref_case.lower()\n",
    "\n",
    "    ref_case_tokens = nltk.word_tokenize(ref_case)\n",
    "\n",
    "    print(\"Radiologist report:\")\n",
    "    print(ref_case)\n",
    "    # print(ref_case_tokens)\n",
    "    print()\n",
    "\n",
    "    with open(gen, \"r\") as f:\n",
    "        gen_case = f.readlines()\n",
    "\n",
    "    gen_case = \".\".join(map(str, gen_case))\n",
    "\n",
    "    gen_case_tokens = nltk.word_tokenize(gen_case)\n",
    "\n",
    "    print(\"Generated report:\")\n",
    "    print(gen_case)\n",
    "    # print(gen_case_tokens)\n",
    "    print(\"---------\\n\")\n",
    "\n",
    "    print(f\"Raw BLEU: {round(corpus_bleu([[ref_case_tokens]],[gen_case_tokens]), 4)}\")\n",
    "    print()\n",
    "\n",
    "    print(\n",
    "        \"Individual 1-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(1, 0, 0, 0))\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 2-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(0, 1, 0, 0))\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 3-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(0, 0, 1, 0))\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 4-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(0, 0, 0, 1))\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    print(\"Adjusted weighting\")\n",
    "    print(\n",
    "        \"Individual 1-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(1, 0, 0, 0))\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 2-gram: %f\"\n",
    "        % corpus_bleu([[ref_case_tokens]], [gen_case_tokens], weights=(0.5, 0.5, 0, 0))\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 3-gram: %f\"\n",
    "        % corpus_bleu(\n",
    "            [[ref_case_tokens]], [gen_case_tokens], weights=(0.33, 0.33, 0.33, 0)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Individual 4-gram: %f\"\n",
    "        % corpus_bleu(\n",
    "            [[ref_case_tokens]], [gen_case_tokens], weights=(0.25, 0.25, 0.25, 0.25)\n",
    "        )\n",
    "    )\n",
    "    print(\"---------\\n\")\n",
    "\n",
    "    bleu = load_metric(\"bleu\")\n",
    "    dataset_bleu = bleu.compute(\n",
    "        predictions=[[gen_case_tokens]], references=[[ref_case_tokens]]\n",
    "    )\n",
    "\n",
    "    print(dataset_bleu)\n",
    "    print()\n",
    "\n",
    "    sacrebleu = load_metric(\"sacrebleu\")\n",
    "    #  SacreBLEU operates on raw text, not tokens\n",
    "    dataset_sacrebleu = sacrebleu.compute(\n",
    "        predictions=[[gen_case]], references=[[ref_case]]\n",
    "    )\n",
    "\n",
    "    print(dataset_sacrebleu)\n",
    "    print()\n",
    "\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    dataset_rouge = rouge.compute(predictions=[[gen_case]], references=[[ref_case]])\n",
    "\n",
    "    print(dataset_rouge)\n",
    "    print()\n",
    "\n",
    "    print(\n",
    "        f\"nltk - Meteor: {round(meteor_score([ref_case_tokens], gen_case_tokens), 4)}\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    meteor = load_metric(\"meteor\")\n",
    "    dataset_meteor = meteor.compute(predictions=[[gen_case]], references=[[ref_case]])\n",
    "\n",
    "    print(dataset_meteor)\n",
    "    print(\"======\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elm4psir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "036f9b356400688fa32ab139d64151f7af42c87240ca002d464048bf8c685a85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
